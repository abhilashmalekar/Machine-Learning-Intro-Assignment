{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1: Explain the differences between AI, ML, Deep Learning (DL), and Data\n",
        "Science (DS).\n",
        "### **Answer:**\n",
        "\n",
        "Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), and Data Science (DS) are interrelated fields in modern technology, but each has distinct characteristics, scope, and applications.\n",
        "\n",
        "**1. Artificial Intelligence (AI):**\n",
        "AI is the broadest concept that refers to creating systems capable of performing tasks that normally require human intelligence. These tasks include problem-solving, reasoning, decision-making, speech recognition, and natural language understanding. AI can be classified as **narrow AI** (task-specific systems like chatbots, recommendation engines) and **general AI** (hypothetical human-like intelligence). AI is thus an umbrella term under which ML and DL fall.\n",
        "\n",
        "**2. Machine Learning (ML):**\n",
        "ML is a **subset of AI** that focuses on enabling machines to learn patterns from data without being explicitly programmed. Instead of rule-based instructions, ML models use algorithms to improve performance with experience. Examples include spam email detection, predictive maintenance, and credit scoring. Techniques such as **supervised, unsupervised, and reinforcement learning** are common in ML.\n",
        "\n",
        "**3. Deep Learning (DL):**\n",
        "DL is a **specialized branch of ML** that uses **artificial neural networks** with multiple layers (hence “deep”). DL is powerful in handling unstructured data like images, audio, and text, which traditional ML struggles with. Applications include image recognition (e.g., face detection), speech assistants (like Siri, Alexa), and autonomous vehicles. DL requires **large datasets and high computing power**.\n",
        "\n",
        "**4. Data Science (DS):**\n",
        "Data Science is a multidisciplinary field that deals with **extracting insights and knowledge from structured and unstructured data**. It combines statistics, mathematics, ML, and domain expertise to analyze data for decision-making. Data scientists use tools like Python, R, SQL, and big data technologies to interpret trends, build predictive models, and communicate insights. Unlike AI/ML, DS is broader as it also emphasizes **data cleaning, visualization, and business interpretation**.\n",
        "\n",
        "**Key Differences (Summary):**\n",
        "\n",
        "* **AI** = the overall goal of creating intelligent machines.\n",
        "* **ML** = the method by which machines learn from data.\n",
        "* **DL** = advanced ML using neural networks for complex data.\n",
        "* **DS** = the practice of analyzing and interpreting data (often using AI/ML).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZGiqX57J6Rhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2: What are the types of machine learning? Describe each with one real-world example\n",
        "### **Answer:**\n",
        "\n",
        "Machine Learning (ML) can be classified into **three main types**: Supervised Learning, Unsupervised Learning, and Reinforcement Learning. Each type differs in how the model learns from data and the kind of problem it solves.\n",
        "\n",
        "---\n",
        "\n",
        "**1. Supervised Learning:**\n",
        "\n",
        "* **Definition:** In supervised learning, the model is trained using a **labeled dataset**, where both input and output are provided. The algorithm learns the mapping function between input features and target output.\n",
        "* **Goal:** To predict outcomes for new, unseen data based on past labeled data.\n",
        "* **Techniques:** Regression (predicting continuous values) and Classification (predicting categories).\n",
        "* **Example:** **Email spam detection** – the model is trained on emails labeled as “spam” or “not spam” and learns to classify new emails correctly.\n",
        "\n",
        "---\n",
        "\n",
        "**2. Unsupervised Learning:**\n",
        "\n",
        "* **Definition:** In unsupervised learning, the dataset contains **only inputs without labeled outputs**. The algorithm tries to find hidden structures, patterns, or relationships in the data.\n",
        "* **Goal:** To group or organize data based on similarity or structure.\n",
        "* **Techniques:** Clustering and Dimensionality Reduction.\n",
        "* **Example:** **Customer segmentation in marketing** – companies use clustering to group customers based on purchase behavior, enabling targeted promotions.\n",
        "\n",
        "---\n",
        "\n",
        "**3. Reinforcement Learning (RL):**\n",
        "\n",
        "* **Definition:** RL is based on **learning through interaction with an environment**. An agent performs actions and receives rewards or penalties based on outcomes. Over time, it learns to maximize cumulative rewards.\n",
        "* **Goal:** To find the best strategy (policy) for decision-making in dynamic environments.\n",
        "* **Example:** **Self-driving cars** – the car (agent) learns to navigate roads safely by receiving rewards for correct actions (e.g., staying in lane) and penalties for mistakes (e.g., collisions).\n",
        "\n",
        "---\n",
        "\n",
        "**Summary:**\n",
        "\n",
        "* **Supervised Learning** → learns with labeled data (prediction tasks).\n",
        "* **Unsupervised Learning** → learns without labels (pattern discovery).\n",
        "* **Reinforcement Learning** → learns through trial and error (decision-making).\n",
        "\n",
        "These three types form the foundation of modern machine learning applications in industries such as healthcare, finance, robotics, and e-commerce.\n",
        "\n"
      ],
      "metadata": {
        "id": "aq2qZyI_7JfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3: Define overfitting, underfitting, and the bias-variance tradeoff in machine learning.\n",
        "### **Answer:**\n",
        "\n",
        "In Machine Learning, building accurate models requires balancing how well the model learns patterns without memorizing or missing key information. Three important concepts are **overfitting, underfitting, and the bias–variance tradeoff.**\n",
        "\n",
        "---\n",
        "\n",
        "**1. Overfitting:**\n",
        "\n",
        "* **Definition:** Overfitting occurs when a model learns the training data **too well**, capturing noise and random fluctuations instead of the general pattern.\n",
        "* **Characteristics:** High accuracy on training data but poor performance on unseen/test data.\n",
        "* **Cause:** Model complexity (too many parameters, deep networks) and insufficient data.\n",
        "* **Example:** A decision tree that memorizes every detail of training examples but fails to generalize to new data.\n",
        "\n",
        "---\n",
        "\n",
        "**2. Underfitting:**\n",
        "\n",
        "* **Definition:** Underfitting happens when the model is **too simple** to capture the underlying patterns in the data.\n",
        "* **Characteristics:** Poor performance on both training and test datasets.\n",
        "* **Cause:** Using models with low complexity (e.g., linear regression for non-linear data), inadequate training, or lack of features.\n",
        "* **Example:** Trying to predict housing prices with only the number of rooms, ignoring other important factors like location and size.\n",
        "\n",
        "---\n",
        "\n",
        "**3. Bias–Variance Tradeoff:**\n",
        "\n",
        "* **Definition:** The bias–variance tradeoff explains the balance between **model simplicity (bias)** and **model flexibility (variance).**\n",
        "\n",
        "  * **High Bias:** Model makes strong assumptions, leading to underfitting.\n",
        "  * **High Variance:** Model is too sensitive to training data, leading to overfitting.\n",
        "* **Goal:** Achieve the right balance where both bias and variance are minimized, resulting in good generalization.\n",
        "* **Example:** In polynomial regression:\n",
        "\n",
        "  * A straight line (high bias, low variance) underfits.\n",
        "  * A very high-degree polynomial (low bias, high variance) overfits.\n",
        "  * A moderate polynomial achieves a balance.\n",
        "\n",
        "---\n",
        "\n",
        "**Summary:**\n",
        "\n",
        "* **Overfitting** → model too complex → memorizes data (low bias, high variance).\n",
        "* **Underfitting** → model too simple → misses patterns (high bias, low variance).\n",
        "* **Bias–Variance Tradeoff** → balancing act to build a model that generalizes well.\n"
      ],
      "metadata": {
        "id": "Wh8C6eIF7pA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4: What are outliers in a dataset, and list three common techniques for handling them.\n",
        "\n",
        "### **Answer:**\n",
        "\n",
        "In Machine Learning, building accurate models requires balancing how well the model learns patterns without memorizing or missing key information. Three important concepts are **overfitting, underfitting, and the bias–variance tradeoff.**\n",
        "\n",
        "---\n",
        "\n",
        "**1. Overfitting:**\n",
        "\n",
        "* **Definition:** Overfitting occurs when a model learns the training data **too well**, capturing noise and random fluctuations instead of the general pattern.\n",
        "* **Characteristics:** High accuracy on training data but poor performance on unseen/test data.\n",
        "* **Cause:** Model complexity (too many parameters, deep networks) and insufficient data.\n",
        "* **Example:** A decision tree that memorizes every detail of training examples but fails to generalize to new data.\n",
        "\n",
        "---\n",
        "\n",
        "**2. Underfitting:**\n",
        "\n",
        "* **Definition:** Underfitting happens when the model is **too simple** to capture the underlying patterns in the data.\n",
        "* **Characteristics:** Poor performance on both training and test datasets.\n",
        "* **Cause:** Using models with low complexity (e.g., linear regression for non-linear data), inadequate training, or lack of features.\n",
        "* **Example:** Trying to predict housing prices with only the number of rooms, ignoring other important factors like location and size.\n",
        "\n",
        "---\n",
        "\n",
        "**3. Bias–Variance Tradeoff:**\n",
        "\n",
        "* **Definition:** The bias–variance tradeoff explains the balance between **model simplicity (bias)** and **model flexibility (variance).**\n",
        "\n",
        "  * **High Bias:** Model makes strong assumptions, leading to underfitting.\n",
        "  * **High Variance:** Model is too sensitive to training data, leading to overfitting.\n",
        "* **Goal:** Achieve the right balance where both bias and variance are minimized, resulting in good generalization.\n",
        "* **Example:** In polynomial regression:\n",
        "\n",
        "  * A straight line (high bias, low variance) underfits.\n",
        "  * A very high-degree polynomial (low bias, high variance) overfits.\n",
        "  * A moderate polynomial achieves a balance.\n",
        "\n",
        "---\n",
        "\n",
        "**Summary:**\n",
        "\n",
        "* **Overfitting** → model too complex → memorizes data (low bias, high variance).\n",
        "* **Underfitting** → model too simple → misses patterns (high bias, low variance).\n",
        "* **Bias–Variance Tradeoff** → balancing act to build a model that generalizes well.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FiBIyEFN77hK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 5: Explain the process of handling missing values and mention one imputation technique for numerical and one for categorical data.\n",
        "\n",
        "### **Answer:**\n",
        "\n",
        "In real-world datasets, **missing values** are common due to errors in data collection, transmission issues, or non-responses. If not handled properly, they can reduce model accuracy, introduce bias, and lead to incorrect conclusions. Handling missing values is, therefore, a crucial step in **data preprocessing.**\n",
        "\n",
        "---\n",
        "\n",
        "**1. Process of Handling Missing Values:**\n",
        "The general steps are:\n",
        "\n",
        "* **Step 1: Identify Missing Data** – Use techniques like `isnull()` or `describe()` in Python/R to detect gaps.\n",
        "* **Step 2: Analyze the Pattern** – Check whether data is missing completely at random (MCAR), missing at random (MAR), or not at random (MNAR).\n",
        "* **Step 3: Choose a Strategy** – Options include:\n",
        "\n",
        "  * **Deletion:** Removing rows/columns with many missing values (only if the proportion is small).\n",
        "  * **Imputation:** Filling missing values with suitable estimates.\n",
        "  * **Model-based Approaches:** Using algorithms like KNN imputer or regression to predict missing values.\n",
        "* **Step 4: Apply and Validate** – Ensure the chosen method does not distort data distribution or relationships.\n",
        "\n",
        "---\n",
        "\n",
        "**2. Imputation Techniques:**\n",
        "\n",
        "* **For Numerical Data:**\n",
        "\n",
        "  * **Mean/Median Imputation** – Replace missing values with the mean (for normally distributed data) or median (for skewed data).\n",
        "  * **Example:** If ages in a dataset are missing, replace missing values with the median age to avoid skew from outliers.\n",
        "\n",
        "* **For Categorical Data:**\n",
        "\n",
        "  * **Mode Imputation** – Replace missing values with the most frequently occurring category.\n",
        "  * **Example:** If “Gender” has missing entries, fill them with the most common category, say “Male” or “Female.”\n",
        "\n",
        "---\n",
        "\n",
        "**Summary:**\n",
        "Handling missing values involves **identifying, analyzing, and applying suitable techniques**.\n",
        "\n",
        "* For **numerical data** → use **mean/median imputation**.\n",
        "* For **categorical data** → use **mode imputation**.\n",
        "\n",
        "Proper handling ensures cleaner datasets and improves the performance of machine learning models.\n",
        "\n"
      ],
      "metadata": {
        "id": "B3y0L5fQ81YQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 6: Write a Python program that:\n",
        "● Creates a synthetic imbalanced dataset with make_classification() from\n",
        "sklearn.datasets.\n",
        "\n",
        "● Prints the class distribution.\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n"
      ],
      "metadata": {
        "id": "3bNaXzBF9HZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 6\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from collections import Counter\n",
        "\n",
        "# Step 1: Create synthetic imbalanced dataset\n",
        "X, y = make_classification(n_classes=2, class_sep=2,\n",
        "                           weights=[0.9, 0.1],   # 90% class 0, 10% class 1\n",
        "                           n_informative=3, n_redundant=1, flip_y=0,\n",
        "                           n_features=5, n_clusters_per_class=1,\n",
        "                           n_samples=1000, random_state=42)\n",
        "\n",
        "# Step 2: Print class distribution\n",
        "print(\"Class distribution:\", Counter(y))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp09Enk69bRM",
        "outputId": "0aaea3c0-9791-4ecd-9bf2-4db87df04cc9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution: Counter({np.int64(0): 900, np.int64(1): 100})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 7: Implement one-hot encoding using pandas for the following list of colors:\n",
        "['Red', 'Green', 'Blue', 'Green', 'Red']. Print the resulting dataframe.\n",
        "(Include your Python code and output in the code box below.)\n"
      ],
      "metadata": {
        "id": "sAyB2KC99ndM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 7\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Given list of colors\n",
        "colors = ['Red', 'Green', 'Blue', 'Green', 'Red']\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(colors, columns=['Color'])\n",
        "\n",
        "# Apply one-hot encoding\n",
        "one_hot_df = pd.get_dummies(df, columns=['Color'])\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "print(one_hot_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTqm_mZ79vrN",
        "outputId": "e60e4fd3-3e2b-4489-e445-f86459dd2035"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Color_Blue  Color_Green  Color_Red\n",
            "0       False        False       True\n",
            "1       False         True      False\n",
            "2        True        False      False\n",
            "3       False         True      False\n",
            "4       False        False       True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 8: Write a Python script to:\n",
        "● Generate 1000 samples from a normal distribution.\n",
        "\n",
        "● Introduce 50 random missing values.\n",
        "\n",
        "● Fill missing values with the column mean.\n",
        "\n",
        "● Plot a histogram before and after imputation.\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "vdXQvpZJ9_fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 8\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Generate 1000 samples from a normal distribution\n",
        "np.random.seed(42)\n",
        "data = np.random.normal(loc=50, scale=10, size=1000)\n",
        "\n",
        "# Step 2: Convert to DataFrame\n",
        "df = pd.DataFrame(data, columns=['Value'])\n",
        "\n",
        "# Step 3: Introduce 50 random missing values\n",
        "missing_indices = np.random.choice(df.index, 50, replace=False)\n",
        "df.loc[missing_indices, 'Value'] = np.nan\n",
        "\n",
        "# Step 4: Fill missing values with column mean\n",
        "mean_value = df['Value'].mean()\n",
        "df['Imputed'] = df['Value'].fillna(mean_value)\n",
        "\n",
        "# Step 5: Plot histograms before and after imputation\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(df['Value'].dropna(), bins=30)\n",
        "plt.title(\"Before Imputation\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.hist(df['Imputed'], bins=30)\n",
        "plt.title(\"After Imputation\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "M2J0D0Kj-O81",
        "outputId": "c02d51cb-e266-456d-f61c-fa6a6571eefa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 9: Implement Min-Max scaling on the following list of numbers [2, 5, 10, 15, 20] using sklearn.preprocessing.MinMaxScaler. Print the scaled array.\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "_X1cmLZp-dLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Given data\n",
        "data = np.array([2, 5, 10, 15, 20]).reshape(-1, 1)\n",
        "\n",
        "# Initialize MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit and transform the data\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "# Print scaled array\n",
        "print(\"Original Data:\\n\", data.flatten())\n",
        "print(\"Scaled Data:\\n\", scaled_data.flatten())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp957QJS-jRB",
        "outputId": "0a5a35c0-c3dd-43bc-9390-458c19195334"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            " [ 2  5 10 15 20]\n",
            "Scaled Data:\n",
            " [0.         0.16666667 0.44444444 0.72222222 1.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 10: You are working as a data scientist for a retail company. You receive a customer\n",
        "transaction dataset that contains:\n",
        "\n",
        "● Missing ages,\n",
        "\n",
        "● Outliers in transaction amount,\n",
        "\n",
        "● A highly imbalanced target (fraud vs. non-fraud),\n",
        "\n",
        "● Categorical variables like payment method.\n",
        "\n",
        "Explain the step-by-step data preparation plan you’d follow before training a machine learning\n",
        "model. Include how you’d address missing data, outliers, imbalance, and encoding.\n",
        "\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "Pl0zyu9y-2Tc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-by-Step Data Preparation Plan\n",
        "\n",
        "Handle Missing Data (e.g., Missing Ages)\n",
        "\n",
        "For numerical variables like age:\n",
        "\n",
        "Use mean/median imputation (median is safer if distribution is skewed).\n",
        "\n",
        "Alternatively, predictive imputation (e.g., KNNImputer).\n",
        "\n",
        "For categorical variables:\n",
        "\n",
        "Use mode imputation or a special category \"Unknown\".\n",
        "\n",
        "Handle Outliers in Transaction Amount\n",
        "\n",
        "Detect outliers using IQR method or Z-score.\n",
        "\n",
        "Options to handle:\n",
        "\n",
        "Cap (winsorize) extreme values.\n",
        "\n",
        "Apply log transformation if highly skewed.\n",
        "\n",
        "Handle Imbalanced Target (Fraud vs Non-Fraud)\n",
        "\n",
        "Common strategies:\n",
        "\n",
        "Oversampling minority class (e.g., SMOTE).\n",
        "\n",
        "Undersampling majority class.\n",
        "\n",
        "Class weights in model training (e.g., in LogisticRegression, RandomForest, XGBoost).\n",
        "\n",
        "Encode Categorical Variables (e.g., Payment Method)\n",
        "\n",
        "One-Hot Encoding for nominal variables (no order).\n",
        "\n",
        "Ordinal Encoding if categories have inherent order.\n",
        "\n",
        "Final Step: Scaling (if needed)\n",
        "\n",
        "Use StandardScaler or MinMaxScaler for algorithms sensitive to scale (e.g., KNN, SVM)."
      ],
      "metadata": {
        "id": "5HQaWFua_M8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Dummy dataset\n",
        "data = {\n",
        "    \"age\": [25, np.nan, 40, 35, np.nan, 60],\n",
        "    \"transaction_amount\": [50, 2000, 100, 75, 50000, 120],\n",
        "    \"payment_method\": [\"card\", \"cash\", \"upi\", \"card\", \"cash\", \"upi\"],\n",
        "    \"fraud\": [0, 0, 1, 0, 0, 1]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Original Data:\\n\", df, \"\\n\")\n",
        "\n",
        "# 1. Handle missing ages (median imputation)\n",
        "age_imputer = SimpleImputer(strategy=\"median\")\n",
        "df[\"age\"] = age_imputer.fit_transform(df[[\"age\"]])\n",
        "\n",
        "# 2. Handle outliers (cap transaction_amount using IQR method)\n",
        "Q1 = df[\"transaction_amount\"].quantile(0.25)\n",
        "Q3 = df[\"transaction_amount\"].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower = Q1 - 1.5 * IQR\n",
        "upper = Q3 + 1.5 * IQR\n",
        "df[\"transaction_amount\"] = np.where(df[\"transaction_amount\"] > upper, upper, df[\"transaction_amount\"])\n",
        "\n",
        "# 3. Encode categorical variables\n",
        "encoder = OneHotEncoder(drop=\"first\", sparse_output=False)  # FIXED for sklearn>=1.2\n",
        "encoded_payment = encoder.fit_transform(df[[\"payment_method\"]])\n",
        "encoded_df = pd.DataFrame(encoded_payment, columns=encoder.get_feature_names_out([\"payment_method\"]))\n",
        "df = pd.concat([df.drop(\"payment_method\", axis=1), encoded_df], axis=1)\n",
        "\n",
        "# 4. Handle imbalance using SMOTE\n",
        "X = df.drop(\"fraud\", axis=1)\n",
        "y = df[\"fraud\"]\n",
        "smote = SMOTE(random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X, y)\n",
        "\n",
        "# Save column names before scaling\n",
        "cols = X_res.columns\n",
        "\n",
        "# 5. Scale features\n",
        "scaler = StandardScaler()\n",
        "X_res_scaled = scaler.fit_transform(X_res)\n",
        "\n",
        "print(\"After Preprocessing (Balanced & Scaled):\")\n",
        "print(pd.DataFrame(X_res_scaled, columns=cols).head())  # FIXED\n",
        "print(\"\\nBalanced Target Distribution:\\n\", y_res.value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "nQWb3NqK_lUA",
        "outputId": "6f7fe11c-5312-40d0-9e75-9dae30907b9b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            "     age  transaction_amount payment_method  fraud\n",
            "0  25.0                  50           card      0\n",
            "1   NaN                2000           cash      0\n",
            "2  40.0                 100            upi      1\n",
            "3  35.0                  75           card      0\n",
            "4   NaN               50000           cash      0\n",
            "5  60.0                 120            upi      1 \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 2, n_samples = 2",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-194114643.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fraud\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0msmote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mX_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Save column names before scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \"\"\"\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    103\u001b[0m         )\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         y_ = (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/imblearn/over_sampling/_smote/base.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             X_new, y_new = self._make_samples(\n\u001b[1;32m    361\u001b[0m                 \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0minequality_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"n_neighbors <= n_samples_fit\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    855\u001b[0m                 \u001b[0;34mf\"Expected {inequality_str}, but \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m                 \u001b[0;34mf\"n_neighbors = {n_neighbors}, n_samples_fit = {n_samples_fit}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 2, n_samples = 2"
          ]
        }
      ]
    }
  ]
}